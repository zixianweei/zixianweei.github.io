[{"categories":["文章翻译"],"content":" FYI 原文来自OpenCV官方文档，本人在翻译过程中进行了简单加工和信息补充。如果您认为侵犯了您的合法权益，请与我联系，我将删除本文。 ","date":"2024-06-24","objectID":"/translations/camera-calibration-using-opencv/:0:0","tags":["OpenCV"],"title":"翻译：OpenCV相机标定","uri":"/translations/camera-calibration-using-opencv/"},{"categories":["文章翻译"],"content":"本文目标 通过本文，我们将会学习与如何使用OpenCV进行相机标定相关的知识。具体的： 由相机导致的图像畸变有哪些类型； 如何通过计算得到相机的内参矩阵和外参矩阵； 如何利用相机的内参矩阵和外参矩阵对图像进行消畸变。 ","date":"2024-06-24","objectID":"/translations/camera-calibration-using-opencv/:1:0","tags":["OpenCV"],"title":"翻译：OpenCV相机标定","uri":"/translations/camera-calibration-using-opencv/"},{"categories":["文章翻译"],"content":"基础知识 基于小孔成像模型的相机会为所拍摄的图像引入图像畸变问题。其中，最主要的畸变类型是：径向畸变（radial distortion）和切向畸变（tangential distortion）。 径向畸变会导致真实场景中的直线变为图像中的曲线。该现象具有越远离图像中心越明显的特点。在图1中，棋盘格两侧使用了两条红色参考线作为对比，可以发现：棋盘格的边缘不再是一条直线；与红色参考线相比，弯曲的线条向图像边缘膨胀；且越靠近图像边缘，线条向外膨胀的现象越明显。如果想要了解更多有关图像畸变的知识，可以参考维基百科中的光学畸变一节。 图1 径向畸变现象展示 具体的，径向畸变可以使用下面的公式表示： $$ \\begin{align*} x_{distorted} \u0026= x(1 + k_{1} r^2 + k_{2} r^4 + k_{3} r^6), \\\\ y_{distorted} \u0026= y(1 + k_{1} r^2 + k_{2} r^4 + k_{3} r^6). \\end{align*} $$ 与径向畸变类似，切向畸变则是由相机镜头所在平面和像平面非严格平行引起的。因此，图像中的部分区域会存在看上去比理论上更靠近的现象。切向畸变可以使用下面的公式表示： $$ \\begin{align*} x_{distorted} \u0026= x + [2p_{1}xy + p_{2}(r^2+2x^2)], \\\\ y_{distorted} \u0026= y + [p_{1}(r^2+2y^2) + 2p_{2}xy]. \\end{align*} $$ 根据径向畸变和切向畸变的表示公式，我们可以使用五个参数表示图像的畸变。这五个参数也被称为畸变参数（distortion coefficients）： $$ \\begin{align*} C_{distortion} = (k_1 \\enspace k_2 \\enspace p_1 \\enspace p_2 \\enspace k_3). \\end{align*} $$ 除畸变参数外，我们还需要一些额外的信息来完成畸变矫正的流程，如相机的内部参数和外部参数。 每个相机的内部参数均不相同，他取决于相机的光学特性。通常情况下，相机的内部参数由相机的焦距$(f_x, fy)$和光心位置$(c_x, cy)$组成。由于每个相机的内部参数都是独有的，因此一旦确定，就可以被所有该相机拍摄的图像复用。一般来说，相机的内部参数会使用一个大小为$3\\times 3$的矩阵表示： $$ \\begin{align*} M_{camera} = \\begin{bmatrix} f_x \u0026 0 \u0026 c_x \\\\ 0 \u0026 f_y \u0026 c_y \\\\ 0 \u0026 0 \u0026 1 \\end{bmatrix}. \\end{align*} $$ 对于外部参数，他通常是由一些旋转和平移的向量组成，用于表示三维空间中物体位置到相机坐标位置的转换。由于每张图像中拍摄的场景都可能存在不同，外部参数往往因拍摄的图像而异。 译者注：坐标转换和坐标空间 这里可以参考图形学渲染管线中的顶点处理阶段进行理解。在变换过程中主要涉及五种坐标空间，目的是为了将三维空间中的物体投影到相机平面中。相关信息可以查阅LearnOpenGL。 对于立体视觉应用，图像畸变是首先需要被消除和矫正的，否则会引起后续处理流程的误差累计或产生错误结果。为了得到用于消除图像畸变的参数，我们需要使用相机拍摄一些精心设计场景。其中，最为常见的场景是棋盘格图像。在精心设计的场景中，我们能够预先知道真实世界中的关键点坐标信息，也可以通过图像处理的方式得到关键点在图像中的相应坐标信息。通过多个这样的信息对，就可以计算得到用于消畸变的畸变参数、相机内外参数等。一般来说，为了得到更好的结果，往往需要对相同的场景拍摄至少10张不同角度的测试图像。 ","date":"2024-06-24","objectID":"/translations/camera-calibration-using-opencv/:2:0","tags":["OpenCV"],"title":"翻译：OpenCV相机标定","uri":"/translations/camera-calibration-using-opencv/"},{"categories":["文章翻译"],"content":"代码详解 如第二节最后所述，我们需要至少10张测试图像用于相机标定。OpenCV的仓库中提供了一组棋盘格图像用于展示相机标定的过程，他们位于仓库的samples/data目录下，名称为left*.jpg。考虑其中任意一张棋盘格图像，我们需要知道的关键信息是一组三维世界中点的坐标和与之对应的二维图像中的坐标。其中，二维图像中点的坐标十分容易获的，他们就是棋盘格图像中任意两个白色或黑色方块的接触点。 对于三维世界中点的坐标，由于每次拍摄时相机和棋盘格图像之间的相对位置不同，我们需要知道他们的$(x, y, z)$坐标。但为了简单起见，我们可以认为拍摄时棋盘格始终位于$XY$坐标平面内，即所有三维世界中点的$z$坐标均为0。此时，实际情况下$z$坐标的变化认为是由相机沿光轴方向前后移动引起的。通过模型的简化，我们在相机标定时仅需知道三维世界中点的$(x,y)$坐标即可。此外，我们还可以进一步简化这些坐标：由于棋盘格大小是已知且固定的，我们就可以使用一组二维索引表示世界中点的坐标，如$(0, 0)$，$(0, 1)$，$(0, 2)$…… 通过索引值计算得到的结果是真实结果的缩放值。若此时可以知道棋盘格方块实际大小，就能够得到三维世界中点的真实坐标。对于本文的示例场景，由于我们并未实际拍摄图像，并不知晓棋盘格方块的大小，所以略过了棋盘格图像块大小的参数（该参数的单位一般是$mm$）。 一般来说，三维世界中点的坐标被称为物点，二维图像中点的坐标被称为像点。 ","date":"2024-06-24","objectID":"/translations/camera-calibration-using-opencv/:3:0","tags":["OpenCV"],"title":"翻译：OpenCV相机标定","uri":"/translations/camera-calibration-using-opencv/"},{"categories":["文章翻译"],"content":"准备阶段 为了能够搜索到棋盘格图像中的像点，我们使用cv2.findChessboardCorners()函数进行处理。该函数需要我们指定棋盘格图像的像点排列情况，如$8\\times 8$或$5 \\times 5$大小的棋盘格。在本文的示例中，我们使用的是$7\\times 6$排列情况的棋盘格。通常情况下，一个$8\\times 8$排列情况的棋盘格能够找到$7 \\times 7$个像点。函数运行后会返回一个表示是否找到指定排列模式的标志位retval。如果retval为True，表示函数找了指定的像点集合。并且该函数返回的像点集合会按顺序排列，例如从左到右从上到下的顺序。 小提示 在给定一组棋盘格图像后，该函数可能无法在任何一张图像中找到符合要求的像点。因此，较好的做法是：启动相机并拍摄图像后，就使用该函数进行像点的检测；一旦能够在拍摄的图像中找到符合要求的像点，就将结果保存到数组中。此外，在两次拍摄之间，可以预留一些时间，用于调整棋盘格的位置和方向。通过重复上述过程，直到所需的物像点对数满足要求。即使是本文使用的13张图像，我们也无法保证每张图像都能够找到物像点对。因此，我们的做法是：读取所有的图像并逐个检测，然后只选取其中能够检测出符合要求像点的图像进行后续处理。除了棋盘格标定板外，我们还可以使用圆形阵列标定板。此时，可以使用cv2.findCirclesGrid()函数搜索符合要求的像点，并且圆形阵列标定板可以使用更少的图像数量完成相机标定。 译者注：OpenCV中支持的标定板类型 截止4.8.0版本，OpenCV的API中支持了棋盘格、圆形网格和CharuCo三种标定板。来源：知乎 译者注：棋盘格的角点排列 一般来说，拍摄长宽两个方向上具有不同方块数的棋盘格。若长宽方块数量相同，得到的结果存在二义性，无法分辨是没有旋转的结果，还是旋转了$180^{\\circ}$的结果。 对于搜索到像点，我们可以使用cv2.cornerSubPix()来进一步提高他们的坐标精度。此外，还可以使用cv2.drawChessboardCorners在图像中绘制精细化后的有序像点集合。上述的所有流程都可以使用下面的代码完成功能实现。 import cv2 import glob import numpy as np # termination criteria criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001) # prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0) objp = np.zeros((6 * 7, 3), np.float32) objp[:, :2] = np.mgrid[0:7, 0:6].T.reshape(-1, 2) # Arrays to store object points and image points from all the images. objpoints = [] # 3d point in real world space imgpoints = [] # 2d points in image plane. images = glob.glob(\"*.jpg\") for fname in images: img = cv2.imread(fname) gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) # Find the chess board corners ret, corners = cv2.findChessboardCorners(gray, (7, 6), None) # If found, add object points, image points (after refining them) if ret == True: objpoints.append(objp) corners2 = cv2.cornerSubPix(gray, corners, (11, 11), (-1, -1), criteria) imgpoints.append(corners2) # Draw and display the corners cv2.drawChessboardCorners(img, (7, 6), corners2, ret) cv2.imshow(\"img\", img) cv2.waitKey(500) cv2.destroyAllWindows() 对于任意一张棋盘格图像，搜索像点并将像点绘制在棋盘格图像中的结果如图2所示。 图2 有序像点的可视化 ","date":"2024-06-24","objectID":"/translations/camera-calibration-using-opencv/:3:1","tags":["OpenCV"],"title":"翻译：OpenCV相机标定","uri":"/translations/camera-calibration-using-opencv/"},{"categories":["文章翻译"],"content":"标定参数 至此，我们已经得到了用于相机的标定的关键信息：物像点对。接下来，我们将使用cv2.calibrateCamera()函数完成相机的标定过程，得到相机的内外参数以及畸变参数。 # ret - 标定状态 # mtx - 相机内参矩阵 # dist - 畸变参数 # rvecs - 旋转向量 # tvecs - 平移向量 ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None) 译者注：张氏标定法 感兴趣的同学可以查看张正友老师于1998年发表的论文A Flexible New Technique for Camera Calibration，其中详细解释了相机标定的过程和数学推导。 ","date":"2024-06-24","objectID":"/translations/camera-calibration-using-opencv/:3:2","tags":["OpenCV"],"title":"翻译：OpenCV相机标定","uri":"/translations/camera-calibration-using-opencv/"},{"categories":["文章翻译"],"content":"图像消畸变 在获得了相机标定参数后，我们就能够完成图像消畸变任务了。并且，OpenCV提供了两种方式来完成这项任务：使用cv2.undistort()函数和使用cv2.remap()函数。但在此之前，我们可以使用cv2.getOptimalNewCameraMatrix()函数对相机内部参数和畸变参数进行优化，优化的结果由自由度参数$\\alpha$控制。消畸变时，会利用标定参数生成变换矩阵对图像进行修改。这一过程中，图像的边缘可能会出现黑边现象。当优化自由度参数$\\alpha=0$时，该函数将会返回一组能够让黑边变得最小的标定参数，此时图像的边缘可能会丢失一些含有信息的像素；当优化自由度参数$\\alpha=1$时，该函数不会针对黑边进行优化，此时消畸变的结果会包含黑边。此外，该函数还会返回一个图像的ROI，用于将图像的黑边裁剪移除。 现在，我们可以读取待处理图像，然后使用cv2.getOptimalNewCameraMatrix()函数优化相机的内部参数和畸变参数。本文使用的是名为left12.jpg的图像，也就是本文的图1。 img = cv2.imread('left12.jpg') h, w = img.shape[:2] newcameramtx, roi = cv2.getOptimalNewCameraMatrix(mtx, dist, (w,h), 1, (w,h)) 使用cv2.undistort()函数 这种方式最为简单，将优化前后的相机内参与畸变参数作为输入传递给cv2.undistort()函数，就可以得到消畸变后的结果。然后，再使用上文提到的ROI对消畸变结果进行裁剪。 # undistort dst = cv2.undistort(img, mtx, dist, None, newcameramtx) # crop the image x, y, w, h = roi dst = dst[y:y+h, x:x+w] cv2.imwrite('calibresult.png', dst) 使用cv2.remap()函数 这种方式与cv2.undistort()不同：他首先使用cv2.initUndistortRectifyMap()函数建立了消畸变处理前后图像的映射关系，然后使用cv2.remap()对待处理图像应用该映射，最终得到消畸变结果。 # undistort mapx, mapy = cv2.initUndistortRectifyMap(mtx, dist, None, newcameramtx, (w,h), 5) dst = cv2.remap(img, mapx, mapy, cv2.INTER_LINEAR) # crop the image x, y, w, h = roi dst = dst[y:y+h, x:x+w] cv2.imwrite('calibresult.png', dst) 但无论使用哪种方式，都能够得到相同的消畸变结果。本文图1的消畸变结果如图3所示。可以发现：图像中原本向边缘膨胀的线条变直了。在完成相机标定和优化后，可以使用numpy中的numpy.savez()或numpy.savetxt()方法保存相机内外参数和畸变参数，以便后续读取使用。 图3 图像消畸变结果示例 ","date":"2024-06-24","objectID":"/translations/camera-calibration-using-opencv/:3:3","tags":["OpenCV"],"title":"翻译：OpenCV相机标定","uri":"/translations/camera-calibration-using-opencv/"},{"categories":["文章翻译"],"content":"重投影误差 重投影误差可以用于估计用于图像消畸变参数的好坏：重投影误差越接近于零，说明消畸变参数越精确。在计算得到相机的内外参数和畸变参数后，我们可以使用cv2.projectPoints函数将物点转换到二维空间得到理论像点；然后，计算理论像点和实际像点之间坐标的欧式距离；最后，计算所有理论像点和实际像点之间欧式距离的算术均值作为重投影误差。 mean_error = 0 for i in range(len(objpoints)): imgpoints2, _ = cv2.projectPoints(objpoints[i], rvecs[i], tvecs[i], mtx, dist) error = cv2.norm(imgpoints[i], imgpoints2, cv2.NORM_L2)/len(imgpoints2) mean_error += error print( \"total error: {}\".format(mean_error/len(objpoints)) ) ","date":"2024-06-24","objectID":"/translations/camera-calibration-using-opencv/:3:4","tags":["OpenCV"],"title":"翻译：OpenCV相机标定","uri":"/translations/camera-calibration-using-opencv/"},{"categories":["文章翻译"],"content":"完整的代码 #include \u003ciostream\u003e #include \u003cmemory\u003e #include \u003cvector\u003e #include \u003copencv2/opencv.hpp\u003e int main() { std::vector\u003cstd::string\u003e inputPaths; // 需要给定输入图像组 std::vector\u003ccv::Mat\u003e inputImages; inputImages.reserve(inputPaths.size()); for (const auto\u0026 inputPath : inputPaths) { cv::Mat inputImage = cv::imread(inputPath); if (inputImage.empty()) { std::cout \u003c\u003c \"Input image is empty. [\" \u003c\u003c inputPath \u003c\u003c \"]\\n\"; return EXIT_FAILURE; } inputImages.push_back(inputImage); } size_t imageCount = inputImages.size(); std::vector\u003ccv::Mat\u003e inputGrayImages; inputGrayImages.reserve(inputImages.size()); for (const auto\u0026 inputImage : inputImages) { cv::Mat inputGrayImage; cv::cvtColor(inputImage, inputGrayImage, cv::COLOR_BGR2GRAY); inputGrayImages.push_back(inputGrayImage); } static std::vector\u003ccv::Point3f\u003e objectPoint = [](const cv::Size\u0026 size) { std::vector\u003ccv::Point3f\u003e points; for (auto h = 0; h \u003c size.height; h++) { for (auto w = 0; w \u003c size.width; w++) { points.emplace_back(w, h, 0.F); } } return points; }(cv::Size(7, 6)); std::vector\u003cstd::vector\u003ccv::Point3f\u003e\u003e objectPoints; objectPoints.reserve(inputImages.size()); std::vector\u003cstd::vector\u003ccv::Point2f\u003e\u003e imagePoints; imagePoints.reserve(inputImages.size()); const cv::Size patternSize(7, 6); const auto criteria = cv::TermCriteria( cv::TermCriteria::Type::EPS + cv::TermCriteria::Type::MAX_ITER, 30, 0.001); for (size_t i = 0; i \u003c imageCount; i++) { std::cout \u003c\u003c inputPaths[i] \u003c\u003c std::endl; std::vector\u003ccv::Point2f\u003e corners; auto ret = cv::findChessboardCorners(inputGrayImages[i], patternSize, corners); if (ret) { objectPoints.push_back(objectPoint); cv::cornerSubPix(inputGrayImages[i], corners, cv::Size(11, 11), cv::Size(-1, -1), criteria); imagePoints.push_back(corners); } } auto imageSize = inputGrayImages.front().size(); cv::Mat cameraMatrix; cv::Mat distCoeffs; std::vector\u003ccv::Mat\u003e rvecs; std::vector\u003ccv::Mat\u003e tvecs; auto ret = cv::calibrateCamera(objectPoints, imagePoints, imageSize, cameraMatrix, distCoeffs, rvecs, tvecs); std::cout \u003c\u003c \"Total error: \" \u003c\u003c ret \u003c\u003c \"\\n\"; cv::Rect validPixROI; auto newCameraMatrix = cv::getOptimalNewCameraMatrix( cameraMatrix, distCoeffs, imageSize, 1.F, imageSize, \u0026validPixROI); for (size_t i = 0; i \u003c imageCount; i++) { cv::Mat undistortImage; cv::undistort(inputImages[i], undistortImage, cameraMatrix, distCoeffs, newCameraMatrix); std::string outputImageName = \"undistortImage_\" + std::to_string(i) + \".png\"; cv::imwrite(outputImageName, undistortImage(validPixROI)); } float meanError = 0.F; for (size_t i = 0; i \u003c objectPoints.size(); i++) { std::vector\u003ccv::Point2f\u003e objectProjectToImagePoints; cv::projectPoints(objectPoints[i], rvecs[i], tvecs[i], cameraMatrix, distCoeffs, objectProjectToImagePoints); auto error = cv::norm(imagePoints[i], objectProjectToImagePoints, cv::NORM_L2); error /= objectProjectToImagePoints.size(); meanError += error; } meanError /= objectPoints.size(); std::cout \u003c\u003c \"Total error: \" \u003c\u003c ret \u003c\u003c \"\\n\"; return 0; } import cv2 import glob import numpy as np from pprint import pprint criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001) obj_point = np.zeros((6 * 7, 3), np.float32) obj_point[:, :2] = np.mgrid[0:7, 0:6].T.reshape(-1, 2) obj_points = [] img_points = [] image_names = [] # 需要给定输入图像组 (w, h) = (0, 0) for image_name in image_names: pprint(\"Current image: [{}]\".format(image_name)) image = cv2.imread(image_name) image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) (w, h) = image_gray.shape[::-1] ret, corners = cv2.findChessboardCorners(image_gray, (7, 6), None) # ret, corners = cv2.findCirclesGrid(image_gray, (7, 6), None) if ret is True: obj_points.append(obj_point) corners_refined = cv2.cornerSubPix(image_gray, corners, (11, 11), (-1, -1), criteria) img_points.append(corners_refined) pprint(\"Image w = {}, h = {}\".format(w, h)) ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(obj_points, img_points, (w, h), None, None) # undistortion image = cv2.imread(image_names[0]) new_camera_mtx, roi = cv2.getOptimalNewCameraMatrix(mt","date":"2024-06-24","objectID":"/translations/camera-calibration-using-opencv/:4:0","tags":["OpenCV"],"title":"翻译：OpenCV相机标定","uri":"/translations/camera-calibration-using-opencv/"},{"categories":["编程语言"],"content":"通常情况下，操作符new用于动态分类内存；并且所分配内存的生命周期将不受作用域管理1。与malloc()方法不同，操作符new会做两件事：分配内存；初始化对象。而placement new则是一种特殊的动态内存方法，其能够在已分配的内存空间上创建对象。因此，placement new只做了一件事：初始化对象。 Creates and initializes objects with dynamic storage duration, that is, objects whose lifetime is not necessarily limited by the scope in which they were created. If placement-params are provided, they are passed to the allocation function as additional arguments. Such allocation functions are known as placement new, after the standard allocation function void* operator new(std::size_t, void*), which simply returns its second argument unchanged. This is used to construct objects in allcated storage. ","date":"2023-09-08","objectID":"/placement-new/:0:0","tags":["C/C++"],"title":"C++中的placement new","uri":"/placement-new/"},{"categories":["编程语言"],"content":"使用方式 #include \u003ciostream\u003e class MyClass { public: MyClass() { std::cout \u003c\u003c \"MyClass::MyClass\\n\"; } ~MyClass() { std::cout \u003c\u003c \"MyClass::~MyClass\\n\"; } MyClass(const MyClass\u0026) = delete; MyClass\u0026 operator=(const MyClass\u0026) = delete; MyClass(MyClass\u0026\u0026) = delete; MyClass\u0026 operator=(MyClass\u0026\u0026) = delete; private: int m1; double m2; }; int main() { { char buf[sizeof(MyClass)]; void* p = buf; MyClass* o = new (p) MyClass(); // placement new o-\u003e~MyClass(); // Explicitly call the destructor for the placed object. } { MyClass* o = new MyClass(); std::cout \u003c\u003c \"o address = \" \u003c\u003c o \u003c\u003c \"\\n\"; o-\u003e~MyClass(); o = new (o) MyClass(); // placement new std::cout \u003c\u003c \"o address = \" \u003c\u003c o \u003c\u003c \"\\n\"; delete o; } return 0; } 上方是一段使用placement new的场景：在栈上申请一段内存后，将这段内存的地址作为参数传递给操作符new。此外，对象的生命周期由用户负责：离开作用域时，系统会自动回收buf；在此之前，需要显式调用对象的析构函数。 ","date":"2023-09-08","objectID":"/placement-new/:1:0","tags":["C/C++"],"title":"C++中的placement new","uri":"/placement-new/"},{"categories":["编程语言"],"content":"使用场景 placement new能够在已分配内存上直接构造对象，省去了内存的分配的过程，可以重复利用已分配空间。但总的来说，并不推荐使用placement new，原因如下2： placement new需要用户自行保证已分配的内存空间能够放置对象，编译器和运行时都不会对空间是否足够进行检查。 已分配空间可能存在对齐问题：虽然理论上已分配空间可以放置对象，但由于内存对齐，实际占用的空间会更大。 总的来说，编译器和运行时不会检查placement new是否正确完成，需要用户自行考虑空间大小内存对齐等问题。不管怎样，placement new不要随意使用，除非迫不得已；如果想要重复利用已分配内存空间，用户应当选择使用内存池管理内存而不使用placement new。 cppreference.com - new expression ↩︎ isocpp - FAQ:Destructors ↩︎ ","date":"2023-09-08","objectID":"/placement-new/:2:0","tags":["C/C++"],"title":"C++中的placement new","uri":"/placement-new/"},{"categories":null,"content":"Hi~，欢迎来到我的小破站。这里记录了我学习C++和图形图像等知识的笔记。此外，还有一些与生活相关的奇怪想法。 如果有啥想说的话可以在最下方评论，我会尽快回复。也可以通过邮件联系到我：zixianwei@foxmail.com。 ","date":"2020-12-21","objectID":"/about/:0:0","tags":null,"title":"关于","uri":"/about/"},{"categories":null,"content":"参与的开源项目 OpenCV: fix compilation error on Windows ARM, use vaddq_f32 instead of += #24043 ","date":"2020-12-21","objectID":"/about/:1:0","tags":null,"title":"关于","uri":"/about/"},{"categories":null,"content":"目前使用的设备 MacBook Pro 13 NUC8i5BEK CPU Intel Core i5-1038NG7 Intel Core i5-8259U 内存 LPDDR4 3733MHz 8GB$\\times$2 DDR4 2666MHz 8GB$\\times$2 ","date":"2020-12-21","objectID":"/about/:2:0","tags":null,"title":"关于","uri":"/about/"},{"categories":["环境搭建"],"content":"本篇记录了在Ubuntu系统中编译Qt4的过程。 ","date":"2020-12-21","objectID":"/ubuntu-1604-compile-qt-483/:0:0","tags":["Linux","Qt"],"title":"Ubuntu16下编译Qt4.8.3源码","uri":"/ubuntu-1604-compile-qt-483/"},{"categories":["环境搭建"],"content":"编译环境 Ubuntu 16.04.7 GCC 4.9 Qt 4.8.3 首先贴出Qt源码的下载地址 https://download.qt.io/archive/qt/。这个网站相对国内的镜像站更全(国内的镜像站似乎没有Qt4源码)，但是缺点是比较慢，有梯子的话应该会更快。 下面就可以在本地计算机上进行编译相关的操作了，在这里我将下载好的源码放在 $HOME/Downloads路径下。大家可以根据自己的实际情况进行相关的修改。 ","date":"2020-12-21","objectID":"/ubuntu-1604-compile-qt-483/:1:0","tags":["Linux","Qt"],"title":"Ubuntu16下编译Qt4.8.3源码","uri":"/ubuntu-1604-compile-qt-483/"},{"categories":["环境搭建"],"content":"解压源码压缩包 这里可以使用系统自带的GUI解压工具解压，也可以在终端中使用命令解压。终端中解压命令为: tar -zxvf qt-everywhere-opensource-src-4.8.3.tar.gz cd qt-everywhere-opensource-src-4.8.3 解压后，使用cd命令进入解压后的路径，后续的主要操作都在这个目录下进行。 ","date":"2020-12-21","objectID":"/ubuntu-1604-compile-qt-483/:2:0","tags":["Linux","Qt"],"title":"Ubuntu16下编译Qt4.8.3源码","uri":"/ubuntu-1604-compile-qt-483/"},{"categories":["环境搭建"],"content":"安装依赖项 这里需要安装的依赖项很多。如果有模块不需要安装，则可以不安装相关依赖。不过这里推荐全部安装，万一以后会用到呢。 sudo apt install -y gcc-4.9 g++-4.9 make cmake gdb build-essential sudo apt install -y libx-dev libxext-dev libxtst-dev sudo apt install -y openssl libssl-dev sudo apt install -y g++-multilib zlib1g-dev autoconf automake libtool sudo apt install -y libgl1-mesa-dev libglu1-mesa-dev sudo apt install -y libglib2.0-dev libalsa-ocaml-dev sudo apt install -y xorg-dev gperf bison flex sqlite sudo apt install -y libxrender-dev libxrandr-dev libedbus-dev libdbus-1-dev sudo apt install -y libgstreamer0.10-dev libgstreamer-plugins-base0.10-dev sudo apt install -y libxt-dev subversion libsqlite3-dev libpng12-dev # 64位机器 sudo apt install -y lib32ncurses5 lib32z1 # 32位机器 sudo apt install -y libx32ncurses5 libx32z1 ","date":"2020-12-21","objectID":"/ubuntu-1604-compile-qt-483/:3:0","tags":["Linux","Qt"],"title":"Ubuntu16下编译Qt4.8.3源码","uri":"/ubuntu-1604-compile-qt-483/"},{"categories":["环境搭建"],"content":"修改相关文件 这里是Qt能否编译成功的关键所在。主要有3个地方需要修改，我将一一说明。 将系统默认的GCC/G++命令链接到刚刚安装的4.9版本的GCC中。需要这一步的原因是，GCC5以上的GCC是始终无法打开WebKit编译选项的，所以如果需要WebKit就需要更换到4.9版本的GCC。 # 建立gcc和g++的软链接 sudo ln -sf /usr/bin/gcc-4.9 /usr/bin/gcc sudo ln -sf /usr/bin/g++-4.9 /usr/bin/g++ 将GCC的C++编译版本调整为C++98标准。默认情况下，编译器似乎是启用了C++11标准，将会出现很多奇怪的错误，例如narrowing conversion相关的错误。这里需要修改两个文件的CXX_FLAGS。 # mkspecs/common/g++-base.conf 第18行 QMAKE_CXX = g++ 改为 QMAKE_CXX = g++ -std=gnu++98 # mkspecs/common/gcc-base.conf 第45行 QMAKE_CXXFLAGS += $$QMAKE_CFLAGS 改为 QMAKE_CXXFLAGS += $$QMAKE_CFLAGS -std=gnu++98 修改JavaScriptCore.pri文件中的内容，这个文件和WebKit编译相关，修改之后WebKit才能编译通过。具体的链接在这里，这是WebKit的一个bug。 sed -i -e '/CONFIG\\s*+=\\s*text_breaking_with_icu/ s:^#\\s*::' \\ src/3rdparty/webkit/Source/JavaScriptCore/JavaScriptCore.pri 到这里，编译Qt4最关键的部分就完成了。 ","date":"2020-12-21","objectID":"/ubuntu-1604-compile-qt-483/:4:0","tags":["Linux","Qt"],"title":"Ubuntu16下编译Qt4.8.3源码","uri":"/ubuntu-1604-compile-qt-483/"},{"categories":["环境搭建"],"content":"编译相关 Qt在默认情况下编译的是动态链接库，也可以通过添加-static选项编译静态库，但是编译静态库是无法启用WebKit的。(我也尝试编译了静态库，死在了最终链接的时候) 编译的流程是先通过configure生成Makefile文件，然后使用make编译，最终install。具体命令如下： ./configure -opensource -nomake demos -nomake examples -nomake tests -silent -webkit make -j4 sudo make install 其中，-nomake选项关闭了Qt例子和测试，这样可以节省编译的时间，有需要的可以打开。 我使用的编译平台是：Intel Core i3-2350M+DDR3-1333MHz 6GB，编译全程耗时大概40分钟左右。如果你的机器更好可以更改make -j4后面的数字。默认情况下，安装路径为：/usr/loca/Trolltech/Qt-4.8.3。如果需要自定义的话，可以在configure的时候使用-prefix选项进行修改，这里我使用的是默认安装路径。 ","date":"2020-12-21","objectID":"/ubuntu-1604-compile-qt-483/:5:0","tags":["Linux","Qt"],"title":"Ubuntu16下编译Qt4.8.3源码","uri":"/ubuntu-1604-compile-qt-483/"},{"categories":["环境搭建"],"content":"添加环境变量 在编译安装完成后，我们在终端中输入qmake，会发现仍未找到相关命令或者并不是我们需要的4.8.3版本。这是因为还需要在系统中添加环境变量才可以使我们自行安装的Qt生效。这里我选择的是更改$HOME/.bashrc文件。这个文件是当前账户bash环境的环境变量控制文件，使用zsh的在$HOME/.zshrc文件中进行相关修改即可。 在环境变量文件的最后添加下面四行： export PATH=\"/usr/loca/Trolltech/Qt-4.8.3/bin:$PATH\" export LD_LIBRARY_PATH=\"/usr/loca/Trolltech/Qt-4.8.3/lib:$LD_LIBRARY_PATH\" export MANPATH=\"/usr/loca/Trolltech/Qt-4.8.3/man:$MANPATH\" export PKG_CONFIG_PATH=\"/usr/loca/Trolltech/Qt-4.8.3/lib/pkgconfig:$PKG_CONFIG_PATH\" 稍微解释下每一个变量是干什么的：PATH主要负责可执行路径，LD_LIBRARY_PATH负责库文件，MANPATH负责终端文档，PKG_CONFIG_PATH负责pkgconfig文件配置。 ","date":"2020-12-21","objectID":"/ubuntu-1604-compile-qt-483/:6:0","tags":["Linux","Qt"],"title":"Ubuntu16下编译Qt4.8.3源码","uri":"/ubuntu-1604-compile-qt-483/"},{"categories":["环境搭建"],"content":"总结 到这里，整个Qt4.8.3编译安装配置都完成了。其实看上去也没啥工作量，但是一开始尝试编译的时候各种报错还是挺难受的。我将我遇到的问题和解决方法整理在这里，欢迎讨论和私信我，我会尽量及时回复。 下一期将介绍FFMpeg编译的相关流程，敬请期待吧。:) ","date":"2020-12-21","objectID":"/ubuntu-1604-compile-qt-483/:7:0","tags":["Linux","Qt"],"title":"Ubuntu16下编译Qt4.8.3源码","uri":"/ubuntu-1604-compile-qt-483/"}]